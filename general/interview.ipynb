{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['h', 'he', 'hel', 'help', 'helpi', 'helpis', 'helpisn', 'helpisno', 'helpisnow', 'helpisnowh', 'helpisnowhe', 'helpisnowher', 'helpisnowhere', 'e', 'el', 'elp', 'elpi', 'elpis', 'elpisn', 'elpisno', 'elpisnow', 'elpisnowh', 'elpisnowhe', 'elpisnowher', 'elpisnowhere', 'l', 'lp', 'lpi', 'lpis', 'lpisn', 'lpisno', 'lpisnow', 'lpisnowh', 'lpisnowhe', 'lpisnowher', 'lpisnowhere', 'p', 'pi', 'pis', 'pisn', 'pisno', 'pisnow', 'pisnowh', 'pisnowhe', 'pisnowher', 'pisnowhere', 'i', 'is', 'isn', 'isno', 'isnow', 'isnowh', 'isnowhe', 'isnowher', 'isnowhere', 's', 'sn', 'sno', 'snow', 'snowh', 'snowhe', 'snowher', 'snowhere', 'n', 'no', 'now', 'nowh', 'nowhe', 'nowher', 'nowhere', 'o', 'ow', 'owh', 'owhe', 'owher', 'owhere', 'w', 'wh', 'whe', 'wher', 'where', 'her', 'here', 'er', 'ere', 'r', 're']\n",
      "87\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import words\n",
    "from itertools import combinations\n",
    "\n",
    "# we need to create all possible divisions of the input string - this solves the problem of word ordering\n",
    "def get_all_substrings(input: str):\n",
    "    length = len(input) + 1\n",
    "    division_list = [input[x:y] for x, y in combinations(range(length), r=2)]\n",
    "\n",
    "    res = []\n",
    "    [res.append(x) for x in division_list if x not in res]\n",
    "    return res\n",
    "\n",
    "division_list = get_all_substrings(\"helpisnowhere\") \n",
    "print(division_list)\n",
    "print(len(division_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'h': 0, 'he': 1, 'hel': 2, 'help': 3, 'helpi': 4, 'helpis': 5, 'helpisn': 6, 'helpisno': 7, 'helpisnow': 8, 'helpisnowh': 9, 'helpisnowhe': 10, 'helpisnowher': 11, 'helpisnowhere': 12, 'e': 13, 'el': 14, 'elp': 15, 'elpi': 16, 'elpis': 17, 'elpisn': 18, 'elpisno': 19, 'elpisnow': 20, 'elpisnowh': 21, 'elpisnowhe': 22, 'elpisnowher': 23, 'elpisnowhere': 24, 'l': 25, 'lp': 26, 'lpi': 27, 'lpis': 28, 'lpisn': 29, 'lpisno': 30, 'lpisnow': 31, 'lpisnowh': 32, 'lpisnowhe': 33, 'lpisnowher': 34, 'lpisnowhere': 35, 'p': 36, 'pi': 37, 'pis': 38, 'pisn': 39, 'pisno': 40, 'pisnow': 41, 'pisnowh': 42, 'pisnowhe': 43, 'pisnowher': 44, 'pisnowhere': 45, 'i': 46, 'is': 47, 'isn': 48, 'isno': 49, 'isnow': 50, 'isnowh': 51, 'isnowhe': 52, 'isnowher': 53, 'isnowhere': 54, 's': 55, 'sn': 56, 'sno': 57, 'snow': 58, 'snowh': 59, 'snowhe': 60, 'snowher': 61, 'snowhere': 62, 'n': 63, 'no': 64, 'now': 65, 'nowh': 66, 'nowhe': 67, 'nowher': 68, 'nowhere': 69, 'o': 70, 'ow': 71, 'owh': 72, 'owhe': 73, 'owher': 74, 'owhere': 75, 'w': 76, 'wh': 77, 'whe': 78, 'wher': 79, 'where': 80, 'her': 81, 'here': 82, 'er': 83, 'ere': 84, 'r': 85, 're': 86}\n"
     ]
    }
   ],
   "source": [
    "# create dict with word and index of found word...\n",
    "# maybe not needed\n",
    "# remove duplicates from list by converting it to dictionary\n",
    "division_dict =  {k: v for v, k in enumerate(division_list)}\n",
    "print(division_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\richa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'e',\n",
       " 'el',\n",
       " 'er',\n",
       " 'ere',\n",
       " 'h',\n",
       " 'he',\n",
       " 'help',\n",
       " 'her',\n",
       " 'here',\n",
       " 'i',\n",
       " 'is',\n",
       " 'l',\n",
       " 'n',\n",
       " 'no',\n",
       " 'now',\n",
       " 'nowhere',\n",
       " 'o',\n",
       " 'ow',\n",
       " 'p',\n",
       " 'pi',\n",
       " 'r',\n",
       " 're',\n",
       " 's',\n",
       " 'snow',\n",
       " 'w',\n",
       " 'where'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import words\n",
    "\n",
    "def get_all_words():\n",
    "\tnltk.download(\"words\")\n",
    "\treturn set(words.words())\n",
    "\n",
    "all_words = get_all_words()\n",
    "\n",
    "# okay now we have the unique words, now we need to check if any of them is in the all_words set\n",
    "# make division_list into set \n",
    "division_set = set(division_list)\n",
    "division_all_intersect = division_set.intersection(all_words)\n",
    "division_all_intersect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'h': 0,\n",
       " 'he': 1,\n",
       " 'help': 3,\n",
       " 'e': 13,\n",
       " 'el': 14,\n",
       " 'l': 25,\n",
       " 'p': 36,\n",
       " 'pi': 37,\n",
       " 'i': 46,\n",
       " 'is': 47,\n",
       " 's': 55,\n",
       " 'snow': 58,\n",
       " 'n': 63,\n",
       " 'no': 64,\n",
       " 'now': 65,\n",
       " 'nowhere': 69,\n",
       " 'o': 70,\n",
       " 'ow': 71,\n",
       " 'w': 76,\n",
       " 'where': 80,\n",
       " 'her': 81,\n",
       " 'here': 82,\n",
       " 'er': 83,\n",
       " 'ere': 84,\n",
       " 'r': 85,\n",
       " 're': 86}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_division_dict = {key: division_dict[key] for key in division_all_intersect}\n",
    "filtered_division_dict = {k: v for k, v in sorted(filtered_division_dict.items(), key=lambda item: item[1])}\n",
    "filtered_division_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'he': 1,\n",
       " 'help': 3,\n",
       " 'el': 14,\n",
       " 'pi': 37,\n",
       " 'is': 47,\n",
       " 'snow': 58,\n",
       " 'no': 64,\n",
       " 'now': 65,\n",
       " 'nowhere': 69,\n",
       " 'ow': 71,\n",
       " 'where': 80,\n",
       " 'her': 81,\n",
       " 'here': 82,\n",
       " 'er': 83,\n",
       " 'ere': 84,\n",
       " 're': 86}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we clear out unnecessary entries\n",
    "for word in list(filtered_division_dict):\n",
    "    if len(word) == 1 and (word != \"a\" or word != \"i\"):\n",
    "        filtered_division_dict.pop(word)\n",
    "\n",
    "filtered_division_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he',\n",
       " 'help',\n",
       " 'el',\n",
       " 'pi',\n",
       " 'is',\n",
       " 'snow',\n",
       " 'no',\n",
       " 'now',\n",
       " 'nowhere',\n",
       " 'ow',\n",
       " 'where',\n",
       " 'her',\n",
       " 'here',\n",
       " 'er',\n",
       " 'ere',\n",
       " 're']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filtered_division_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
